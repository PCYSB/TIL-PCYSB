06-3 캐시 메모리

# 저장 장치 계층 구조
모든 사용자들은 빠르고 용량이 큰 저장 장치를 원한다. 아쉽게도 이것은 양립하기 힘들다.
저장 장치는 일반적으로 다음과 같은 명제를 따른다.
1. CPU와 가까운 저장장치는 빠르고, 멀리 있는 저장 장치는 느리다.
- CPU와 가장 가까운 레지스터는 일반적으로 RAM보다 용량은 작지만, 접근 시간이 압도적으로 빠르고 가격이 비싸다.
2. 속도가 빠른 저장 장치는 저장 용량이 작고, 가격이 비싸다.
- USB 메모리보다 CPU에 더 가까운 RAM은 접근 시간이 훨씬 더 빠르지만, 같은 용량이라 할지라도 가격은 더 비싸다.

즉 낮은 가격대의 대용량 저장 장치를 원한다면 느린 속도는 감수해야 하고, 빠른 메모리를 원한다면 작은 용량과 비싼 가격은 감수해야 한다.
이처럼 컴퓨터가 사용하는 저장 장치들은 'CPU에 얼마나 가까운가'를 기준으로 계층적으로 나타낼 수 있다. 이를 **저장 장치 계층 구조**라고 한다.

# 캐시 메모리
CPU가 메모리에 접근하는 속도는 레지스터에 접근하는 속도보다 느리다. 하지만 CPU는 프로그램을 실행하는 과정에서 메모리에 빈번히 접근해야만 한다. CPU가 아무리 빠르더라도 메모리에 접근하는 속도가 그에 따라가지 못한다면 CPU의 발전은 아무 소용이 없을 것이다. 그래서 등장한 저장 장치가 캐시 메모리이다.

**캐시 메모리**
- CPU와 메모리 사이에 위치한다.(메모리 보다 CPU에 가깝다)
- 레지스터보다 용량이 크고 메모리보다 빠른 SRAM 기반의 저장 장치이다.
- CPU의 연산 속도와 메모리 접근 속도의 차이를 조금이나마 줄이기 위해 탄생함

CPU가 매번 메모리에 왔다 갔다 하는 것은 시간이 오래 걸리니, 메모리에서 CPU가 사용할 일부 데이터를 미리 캐시 메모리로 가지고 와서 활용하자 라는 것이다.
비유를 하자면 집에서 먼 대형 마트와 집에서 가까운 편의점 정도의 느낌으로 생각하면 될 것 같다.

컴퓨터 내부에는 여러 개의 캐시 메모리가 있다. 이 캐시 메모리들도 CPU와 가까운 순서대로 계층을 구성한다. L1 > L2 >L3
용량은 L3이 가장 크고 속도는 L1이 가장 빠르다(계층) 
멀티 코어 프로세서에서의 경우 L1,L2,L3 캐시는 코어마다 있거나 or 공유를 한다.


# 참조 지역성 원리
캐시 메모리는 메모리보다 용량이 작다. 그렇기 때문에 메모리에 있는 모든 내용을 저장할 수 없다.
캐시 메모리는 CPU가 사용할 법한 대상을 예측하여 저장한다. 이때 자주 사용될 것으로 예측한 데이터가 실제로 들이맞아 캐시 메모리 내 데이터가 CPU에서 활용될 경우를 **캐시 히트**라고 한다.
반대로 예측이 틀려 메모리에서 필요한 데이터를 직접 가져와야 하는 경우를 **캐시 미스**라고 한다. 이 경ㅇ 캐시 메모리의 이점을 활용할 수 없기 때문에 자주 발생시 성능이 떨어짐
여기서 캐시가 히트되는 비율을 **캐시 적중률**이라 하고 (캐시 히트 횟수)/ (캐시 히트 횟수 + 캐시 미스 횟수) 이렇게 계산

이제 참조 지역성의 원리를 알아 보자 이는 캐시 메모리는 한 가지 원칙에 따라 메모리로부터 가져올 데이터를 결정하는데 CPU가 메모리에 접근할 때의 주된 경향을 바탕으로 만들어진 원리이다.
1. CPU는 최근에 접근했던 메모리 공간에 다시 접근하려는 경향이 있다.(시간 지역성)
- 우리가 프로그래밍을 할 때 변수를 사용할 때 여러변 변수에 접근할 수 있는 것과 같은 느낌이다.
2. CPU는 접근한 메모리 공간 근처를 접근하려는 경향이 있다.(공간 지역성)

